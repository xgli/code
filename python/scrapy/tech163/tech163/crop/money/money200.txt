专家 建议 把 人类 价值 " 植 入 " 机器人   防范 人工智能 
10月 20日 ， 在 美国 加利福尼亚州 拉古纳 比 奇 举行 的 一 场 科技 大会 上 ， 情感 “ 佩 珀 ” 和 一 位 与会者 拍手 。 ( 路透社 ) 外 媒 称 ， 随着 人工智能 技术 越来越 先进 ， 人们 愈发 担心 ， 可能 变成 一 种 威胁 。 据 加利福尼亚 大学 伯克利 分校 计算机 学 教授 斯图尔特·拉塞尔 说 ， 这种 危险 是 可以 避免 的 ， 如果 我们 能够 解决 如何 把 变成 可 编程 的 代码 。 据 美国 石英 财经 网站 11月 1日 报道 ， 拉塞尔 说 ， 在 机器人 领域 ， “ 道德 哲学 将 是 一个 非常 重要 的 产业 部门 ” 。 他 指出 ： “ 随着 机器人 从事 更加 复杂 的 任务 ， 我们 绝对 有 必要 把 我们 人类 的 道德 转化 为 人工智能 语言 。 ” 比如说 ， 如果 机器人 在 房子 里 做 杂务 —— 预计 未来 几十 年 将 会 出现 这种 场面 —— 的话 ， 你 可 不 想 机器人 把 宠物 猫 放 进 烤箱 里 ， 给 饥肠辘辘 的 孩子 们 做 顿 大餐 。 拉塞尔 说 ： “ 你 会 希望 给 那个 机器人 预先 载入 一 大 套 人类 价值 。 ” 人们 已 将 基本 的 人类 价值 编入 了 一些 机器人 的 程序 。 玛丽 女王 大学 计算机 学 教授 彼得·麦克欧文 说 ， 可 移动 机器人 就 被 编入 了 与 人类 保持 适当 距离 的 程序 。 他 说 ： “ 这 是 机器人 行为 可 被 视为 体现 某种 价值 的 一个 极为 简单 的 例子 。 如果 机器人 在 你 和 别人 说 话 时 靠近 你们 的 私人 空间 ， 你 就 会 认为 ， 这 不 是 一个 有 教养 的 人 会 做 的 事情 。 ” 创造 更 复杂 的 、 具备 道德 规范 的 机器人 是 可能 的 ， 但 条件 是 我们 要 找到 把 人类 价值 设定 成 明确 规则 的 办法 。 麦克欧文 说 ： “ 这种 价值 设定 工程 要 有 研究 人类 价值 的 专家 参与 进来 ， 其中 包括 哲学家 、 心理学 家 、 人种学 家 以及 外行 人士 。 就 像 你 把 专业 知识 转化 成 一 套 规则 一样 ， 你 可以 将 这个 讨论 组 提供 的 信息 转化 成 一 系列 规则 。 ” 此外 ， 机器人 还 可以 选取 根据 有关 人类 行为 的 大 套 数据 制成 的 模型 来 学习 人类 价值 。 麦克欧文 说 ， 只有 在 程序员 不 负 责任 的 情况 下 ， 机器人 才 会 成为 一 种 危险 。 他 说 ： “ 就 机器人 违反 人类 价值 这 一 问题 ， 人们 最 担心 的 是 ， 如果 人类 因为 没有 进行 充分 测试 而 没有 给 机器人 正确 编程 的话 ， 机器人 就 不 会 有 充分 的 安全 保障 ， 它们 就 会 有 办法 去 打破 某种 禁忌 。 ” 简单 的 方法 是 ， 当 出现 特殊 情况 时 ， 给 机器人 编入 让 人 去 检查 机器人 行为 是否 正确 的 程序 。 麦克欧文 说 ： “ 如果 机器人 不 确定 一 种 动物 是否 适合 被 放 进 微波炉 时 ， 它 可以 停 下来 ， 发出 哔 哔 的 信号 声 ， 以 请求 人 给 出 指示 。 ” 把 人类 价值 编成 程序 最 困难 的 一 步 是 ， 要 确定 什么 才 是 我们 认为 的 道德 行为 ， 以及 如何 制定 一 套 道德 规则 。 如果 我们 有 了 答案 ， 那么 机器人 对 人类 就 会 是 有益 的 。 